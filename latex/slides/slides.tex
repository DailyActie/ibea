\documentclass[12pt]{beamer}
\usepackage{framed}
\usepackage{amsmath} 
\usepackage{amssymb}
\usepackage{bm}
\usepackage{dsfont}
\usepackage{appendixnumberbeamer}
\usepackage{algorithm}
\usepackage{algorithmic}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
%\usepackage{tgheros}
%\renewcommand*\familydefault{\sfdefault} %% Only if the base font of the document is to be sans serif
\usetheme{metropolis}
\usecolortheme{default}
\usefonttheme[onlymath]{serif}
%\beamertemplatenavigationsymbolsempty
%\hypersetup{pdfpagemode=UseNone} % don't show bookmarks on initial view

% a few macros
\newcommand{\bi}{\begin{itemize}}
\newcommand{\ei}{\end{itemize}}
\newcommand{\ig}{\includegraphics}

\title{Indicator-based Evolutionary Algorithm}
\author{Karim Kouki \and Ahmed Mazari \and Daro Ozad \\ \and Mihaela Sorostinean \and Aris Tritas}

\institute{
	M.Sc. Machine Learning, Information and Content - 
	University of Paris-Saclay
}
\date{\today}
\subject{Optimization}

\begin{document}

  \begin{frame}
  	\titlepage
  \end{frame}
  
  \begin{frame}
    \frametitle{Outline}
    \bi
    \item Motivation
    \item IBEA setting
    \item Implementation \& Tests
    \item Results
    \item Discussion
    \ei
    
  \end{frame}
  
    \begin{frame}
    \frametitle{Goals}
    \textbf{Explore} seminal approaches for evolutionary algorithms
    
	\textbf{Benchmark and compare} algorithms using the COCO platform.
    
  \end{frame}
    
    \begin{frame}
    \frametitle{Setting}
    
	Black-box multi-objective optimization: learn $f$    $$f: \mathbb{R}^n \rightarrow \mathbb{R}^k$$
    
    \textbf{Pareto optimal approximation set} \newline
	Non-dominated set of solution vectors. \note{
    definition of domination relation.}
	
	\textbf{Indicator function:} \newline
	Subjective (\textit{a priori}) preference information. 
  \end{frame}
  
    \begin{frame}
    \frametitle{Indicators}
    Which choice of indicator? Impact on optimization?
    \bi 
    \item Epsilon indicator  \note{simplest possible}
    \item Hyper-volume indicator \note{theoretical analysis}
    \ei
    
   
    Fitness function: scalarize an individual's utility
    
  \end{frame}
  
  
    \begin{frame}
    \frametitle{Recombination}
    
    Different recombination operators.
    
    Choosing a recombination probability.
    
  \end{frame}

  \begin{frame}
    \frametitle{Simulated Binary Crossover}
    \textbf{Goal:} control the domain in which offspring is generated.
    
    \textbf{`Spread` distribution } approximated by ``proxy'' distributions
    
    Contracting $ c(\beta) = 0.5(n_c +1)\beta^{n_c}, \beta \leq 1$
    
	Expanding $ e(\beta) = 0.5(n_c +1)\frac{1}{\beta^{n_c+2}}, \beta > 1$
        
    Distribution index: $n_c \in \mathbb{N} \implies$ find optimal value?
  \end{frame}
    
    \begin{frame}
    \frametitle{Variation operators}
    \subtitle{Low mutation probability}
    Adaptating the step-size: essential to find targets \textbf{fast}.
    
  \end{frame}
  
    \begin{frame}
    \frametitle{Implementation}
	Python \& NumPy    
  \end{frame}
  
      \begin{frame}
    \frametitle{Results - few objectives}
    Success (comparatively to other approaches)
    \bi
    \item Separable
    \item moderate
    \item weakly-structured    
    \ei
    
	Fails in:
	\bi 
	\item multi-modality
	\item ill-conditioning
	\ei
	
  \end{frame}
  
        \begin{frame}
    \frametitle{Results - many objectives}
    Intrisically more difficult problem.
    
    Performance w.r.t random search?
    
    Explain difference between author results on comparison to NSGA-II (better) and our own (worse). Possible causes: budget, implementation of the mutation operator.
     
    Higher impact of multi-modality and ill-conditioning?
  \end{frame}

      \begin{frame}
    \frametitle{Discussion}
    Online parameter tuning.
    
    Hyper-parameters tuning.
    
    Choice of the indicator function.
  \end{frame}
  
  \begin{frame}
  \centering{
  Thank you for your attention!
  
  Questions \& Answers
  }
  \end{frame}
  
    
  
\begin{frame}[allowframebreaks]
  \frametitle<presentation>{References}    
\begin{thebibliography}{}
\beamertemplatearticlebibitems
\bibitem[Zitzler and Künzli]{ibea} Eckart Zitzler and Simon Künzli, “Indicator-Based Selection in Multiobjective Search”. In Parallel Problem Solving from Nature (PPSN 2004), pp. 832-842, 2004.
\bibitem[Kalyanmoy and Agrawal]{sbx} Deb, Kalyanmoy, and Ram B. Agrawal. "Simulated binary crossover for continuous search space." Complex Systems 9.3 (1994): 1-15.
\end{thebibliography}
\end{frame}
\end{document}
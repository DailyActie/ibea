\documentclass[10pt]{beamer}
\usepackage{framed}
\usepackage{amsmath} 
\usepackage{amssymb}
\usepackage{bm}
\usepackage{dsfont}
\usepackage{appendixnumberbeamer}
\usepackage{algorithm}
\usepackage{algorithmic}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
%\usepackage{tgheros}
%\renewcommand*\familydefault{\sfdefault} %% Only if the base font of the document is to be sans serif
\usetheme{metropolis}
\usecolortheme{default}
\usefonttheme[onlymath]{serif}
%\beamertemplatenavigationsymbolsempty
%\hypersetup{pdfpagemode=UseNone} % don't show bookmarks on initial view

% a few macros
\newcommand{\bi}{\begin{itemize}}
\newcommand{\ei}{\end{itemize}}
\newcommand{\ig}{\includegraphics}

\title{Benchmarking of the \\ Indicator-based Evolutionary Algorithm}
\author{Karim Kouki \and Ahmed Mazari \and Daro Heng \\ \and Mihaela Sorostinean \and Aris Tritas}

\institute{
	M.Sc. Machine Learning, Information and Content - 
	University of Paris-Saclay
}
\date{\today}
\subject{Optimization}

\begin{document}

  \begin{frame}
  	\titlepage
  	\note{
  	Study and Implementation of IBEA = Indicator Based Evolutionary Algorithm
Additive Epsilon-Indicator}
  \end{frame}
  
  \begin{frame}
    \frametitle{Outline}
    \bi
    \item Motivation
    \item IBEA setting
    \item Implementation \& Tests
    \item Results
    \item Discussion
    \ei
    
  \end{frame}
  
    \begin{frame}
    \frametitle{Motivation}
    \textbf{Explore} seminal approaches for evolutionary algorithms
    
	\textbf{Benchmark and compare} algorithms using the COCO platform.
    Measure performance in terms of: 
	\bi
    \item Average Runtime 
    \item Convergence speed
	\item ECDF
	\ei
  \end{frame}
    
    \begin{frame}
    \frametitle{Setting}
      \begin{columns}[t]
    \begin{column}{.5\textwidth}
     \begin{block}{
	Multi-objective optimization}
	
    \vspace{10pt}
	\small{
	Given unknown $f: \mathbb{R}^n \rightarrow \mathbb{R}^k$, find
	
	$x^* = \min(f_1(x), f_2(x), ..., f_k(x))$ \newline
	s.t $x \in X$
	}
	
	
    \vspace{10pt}
    \textbf{Pareto optimal approximation set} \newline
	 \note{
    definition of domination relation.}
	
	\textbf{Indicator function:} \newline
	Subjective (\textit{a priori}) preference information.
    \end{block}
    \end{column}
    \begin{column}{.5\textwidth}
    \begin{block}{Non-dominated set of solution vectors.}
    \ig[width=\textwidth]{pareto_front.png}
    \end{block}
    \end{column}
  \end{columns}
  \end{frame}
  
 \begin{frame}
 \frametitle{IBEA Design}
    \bi
    \item MOEA Design: historically based on false assumptions
	The user has implicit contradictory preferences: maximize {diversity,convergence}
		$\rightarrow$ not even compliant with the Pareto dominance relation
		
	\item Choice of INDICATOR: implements user's preferences
	 $\rightarrow$ actually compliant with the Pareto dominance relation
	\item Fitness assignment phase: uses indicator that specifies the user's preference through fitness function
	\ei

	\textbf{Examples of Indicators:}
	\bi
		\item $I_{\epsilon +}$: implemented, low computation time, conservativity
		
		\item $I_{HD}$: implement by another group, it has more of an average population behavior
	\ei
 
  \end{frame}  
  
%    \begin{frame}
%    \frametitle{Indicators}
%    How to take into account user's preference
%    Which choice of indicator? Impact on optimization?
%    \bi 
%    \item Epsilon indicator  \note{simplest possible} \newline
%     Min. distance to improve on the Pareto Set Approximation 
%
%    \item Hyper-volume indicator \note{theoretical analysis}
%    \ei
%    
%   
%    Fitness function: scalarize an individual's utility	
%    
%  \end{frame}
  
     \begin{frame}
    \frametitle{Implementation}
    \textbf{Input:} population size, max generations, budget, fitness scaling factor 
\textbf{Output:} approximation of the Pareto-Set \newline
\textbf{Steps:} 
		\begin{enumerate}
		\item Initialization
        \item Fitness Assignment
        \item Environmental Selection
        \item  Termination Criteria
        \item  Mating Selection
        \item  Variation  (recombination \& mutation)
        \end{enumerate}
  \end{frame}
    \begin{frame}
    \frametitle{Recombination}
    
    Different recombination operators.
    \bi
    \item One point crossover
    \item Intermediate weighting
    \item SBX
    \ei
    \note{Choosing a recombination probability.}
    
  \end{frame}

  \begin{frame}
    \frametitle{Simulated Binary Crossover}
    \textbf{Goal:} control the domain in which offspring is generated.
    
    \textbf{`Spread` distribution } approximated by ``proxy'' distributions
    
    Contracting $ c(\beta) = 0.5(n_c +1)\beta^{n_c}, \beta \leq 1$
    
	Expanding $ e(\beta) = 0.5(n_c +1)\frac{1}{\beta^{n_c+2}}, \beta > 1$
        
    Distribution index: $n_c \in \mathbb{N} \implies$ find optimal value?
  \end{frame}
  
   \begin{frame}
    \frametitle{Simulated Binary Crossover \footnote{Kalyanmoy Deb, S Karthik, Tatsuya Okabe, GECCO 2007}}
    \ig[width=\textwidth]{sbx.png}
  \end{frame}
    
    \begin{frame}
    \frametitle{Variation operator}
    \note{Low mutation probability}
    Adaptating the step-size: essential to find targets \textbf{fast}.
    
  \end{frame}
 
  
      \begin{frame}
    \frametitle{Results}
    Success (comparatively to other approaches)
    \bi
    \item Separable
    \item moderate
    \item weakly-structured    
    \ei
    
	Fails in:
	\bi 
	\item multi-modality
	\item ill-conditioning
	\ei
	Dimensionality of search space.	
  \end{frame}
  
%        \begin{frame}
%    \frametitle{Results - high dimensional problems}
%    Intrisically more difficult problem.
%    
%    Performance w.r.t random search?
%    
%    Explain difference between author results on comparison to NSGA-II (better) and our own (worse). Possible causes: budget, implementation of the mutation operator.
%     
%    Higher impact of multi-modality and ill-conditioning?
%  \end{frame}
    \begin{frame}[b]
  \vspace{10pt}
  \frametitle{Discussion - variance step-size}
  Why does isotropic gaussian works better for some ill-conditioned and multimodal functions than derandomized ?
  \centering{\ig[width=0.7\textwidth]{Rastrigin.png}}
    \end{frame}
    
      \begin{frame}
  \frametitle{Discussion - indicator function}
\textbf{	Tradeoffs to consider}
  	\bi
  	
  	\item problem-specific preference information vs. generality of the indicator \\
  	\item precision vs. computational complexity
  	\note{
	
	\item Adapt derandomized for mutlimodals and ill-conditioned functions ?
\item Think about a different way to tune  the scaling factor the  C in the fitness
\item Online parameters tuning according to the learned hyper parameter
}
\ei
  \end{frame}
 

  \begin{frame}
  \centering{
  Thank you for your attention!
  
  Questions \& Answers
  }
  \end{frame}
  
    
  
\begin{frame}[allowframebreaks]
  \frametitle<presentation>{References}    
\begin{thebibliography}{}
\beamertemplatearticlebibitems
\bibitem[Zitzler and Künzli]{ibea} Eckart Zitzler and Simon Künzli, “Indicator-Based Selection in Multiobjective Search”. In Parallel Problem Solving from Nature (PPSN 2004), pp. 832-842, 2004.
\bibitem[Kalyanmoy and Agrawal]{sbx} Deb, Kalyanmoy, and Ram B. Agrawal. "Simulated binary crossover for continuous search space." Complex Systems 9.3 (1994): 1-15.
\end{thebibliography}
\end{frame}
\end{document}
